{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab394d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.metrics import f1_score, classification_report, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75a333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/cases/Sonar/Sonar.csv')\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07a92b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:08<00:00,  3.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning rate</th>\n",
       "      <th>n_est</th>\n",
       "      <th>max depth</th>\n",
       "      <th>log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.136842</td>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.443439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.453560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.454564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.394737</td>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.513560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.173684</td>\n",
       "      <td>50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.531296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.431579</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.026044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.763158</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.026939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.112179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.218453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.615789</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.563847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     learning rate  n_est  max depth  log loss\n",
       "10        0.136842     50        3.0  0.443439\n",
       "1         0.100000     50        3.0  0.453560\n",
       "4         0.100000    100        3.0  0.454564\n",
       "73        0.394737     50        3.0  0.513560\n",
       "19        0.173684     50        3.0  0.531296\n",
       "..             ...    ...        ...       ...\n",
       "81        0.431579     50        NaN  4.026044\n",
       "162       0.763158     50        NaN  4.026939\n",
       "174       0.800000    100        NaN  4.112179\n",
       "177       0.800000    200        NaN  4.218453\n",
       "134       0.615789    200        5.0  4.563847\n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = np.linspace(0.1,0.8,20)\n",
    "n_est = [50,100,200]\n",
    "m_dp = [None,3,5]\n",
    "scores = []\n",
    "\n",
    "for e in tqdm(eta):\n",
    "    for n in n_est:\n",
    "        for m in m_dp:\n",
    "            gbc = GradientBoostingClassifier(learning_rate=e, n_estimators=n, max_depth=m)\n",
    "            gbc.fit(X_train,y_train)\n",
    "            y_pred_proba = gbc.predict_proba(X_test)\n",
    "            scores.append([e,n,m,log_loss(y_test,y_pred_proba)])\n",
    "\n",
    "scores = pd.DataFrame(scores, columns=['learning rate', 'n_est', 'max depth', 'log loss'])\n",
    "scores.sort_values(by='log loss', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1ab43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
